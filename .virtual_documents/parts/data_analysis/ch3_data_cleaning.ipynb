


#| echo: false
from myutils.functions import question_box, list_to_html, code_block





import pandas as pd
data_file = 'data/data.csv'
df = pd.read_csv(data_file)
print(df.shape)


column_names = df.columns
df.head(5)





#| echo: false
question = 'Is there any NaN in the first column? How many are they?'
process = 'Go through all the 36151 entries of the first column and look for NaN values.'
tools = list_to_html([
    '<code>pandas</code> column selector method <code>.iloc</code>;',
    '<code>pandas</code> method <code>.is_na</code>;',
    'Python function <code>.sum()</code>;',
    'Python function <code>print()</code>.'
    ])
code = list_to_html([
    '<code>arr_year = df.iloc[:,0]</code>, we first select the first column of the DataFrame using the \
    <code>pandas</code> method <code>.iloc[]</code> and we store the selected column in the new \
    variable <code>arr_year</code> (we already used this method in the previous chapter);',
    
    '<code>arr_year_na = arr_year.isna()</code>, we apply the <code>pandas</code> method <code>.isna()</code>. \
    When we apply the <code>.isna()</code> method, we obtain a result with the same dimensions of the \
    object we applied it to, containing either True or False depending on if the corresponding value is \
    a NaN (or na, non arithmetic) value or not. Indeed the result of this method just answers the question: \
    is this value na? \
    We store the result in the variable <code>arr_year_na</code> (you are free to use a more descriptive name);',
    
    '<code>print(arr_year_na.sum())</code>, in Python the boolean values True and False are equivalent to 1 and 0, \
    respectively. This means that \
    if we have an array (a list or sequence of values) containing True and False, if we sum all the values, \
    we would obtain the number of True values (as they count as 1 and everything else counts as 0). These \
    True values correspond to the cases when  the method <code>.isna()</code> found a NaN, so that summing \
    all these values means, as a matter of fact, counting how many NaNs have been found.'
    ])
wiz_code = '<code>print(df.iloc[:,0].isna())</code>, we can apply methods and function one after another, \
using less coding lines and saving space in our computer memory'
question_box(question=question,process=process,tools=tools,code=code,wiz=wiz_code)


arr_year = df.iloc[:,0]
arr_year_na = arr_year.isna()
print(arr_year_na)
print('Total number of NaNs in the first column:',arr_year_na.sum())


solution = 'The first column contains 1 NaN value'
question_box(solution=solution)





#| echo: false
question = "Where is the NaN value located in the first column?"
process = 'Go through all the 36151 entries of the first column and look for the NaN value.'
tools = list_to_html([
    'Python masking.'
    ])
code = list_to_html([
    '<code>df[arr_year_na]</code>, here we will use one of the most useful features when working with \
    DataFrames: masking. From our previous coding, arr_year_na is an object with the same shape and \
    features of the first column, but instead of containing years, it contains True and False values, \
    where True corresponds to NaNs found applying the method <code>.isna()</code>. If we consider \
    our DataFrame <code>df</code>, we can use this object to select data from it. What are we going to \
    select? Well, <code>arr_year_na</code> has a name, and that is the name of the first column, so we \
    will select that. We will also select only the rows where <code>arr_year_na</code> is True.'
])
question_box(question=question,process=process,tools=tools,code=code)


df[arr_year_na]


#| echo: false
solution = 'The row containing a NaN in the first column ("Year of arrival at port of disembarkation") has index 32248, \
it misses information about its itinerary (only the starting port is present) and number of captives, \
and its ID is 91909'
question_box(solution=solution)





#| echo: false
question = 'Which column has NaNs? How many are they?'
process = 'Go through the DataFrame columns one by one and count the NaNs'
tools = list_to_html([
    '<pandas> method <code>.isna()</code>;',
    '<pandas> method <code>.sum()</code>;',
    'Python function <code>print()<code>;',
    'Python <code>for</code> loop'
])

code_block1 = code_block([
    'for column_name in column_names:',
    '    selected_column = df[column_name]',
    '    selected_column_na = selected_column.isna()',
    '    n_nan = selected_column_na.sum()',
    '    print(column_name,"has",n_nan,"NaN")'
])
code = code_block1 + \
    ', we start with a for loop scrolling all the elements contained in the variable <code>column_names</code>. \
    In this variable we previously stored all the column names. In this way the variable <code>column_name</code> \
    will containg a single column name for each iteration of the loop. We then use the column name to select that \
    specific column in our DataFrame, storing this selected column in the variable <code>selected_column</code>. \
    We apply the method <code>.isna()</code> to the selected column to obtain, instead of a column of numerical or \
    string values, a column of True and False (boolean) values. We use the method <code>.sum()</code> to sum all \
    the True and False values. Keeping in mind that True is equivalent to 1 and False to 0, this will result in \
    counting all the NaN values in the selected column. We store this last result in the variable <code>n_nan</code>. \
    We finally print this result, together with the name of the selected column, using the python function <code>print()</code>.'
wiz_code_block = code_block([
    'for i,column_name in enumerate(column_names):',
    '    print(f"{i}) {column_name} has {df[column_name].isna().sum()} NaN")'
])
wiz_code = wiz_code_block + \
    ', we can apply the methods described above one after another, without storing any intermidiate result in a new \
    variable. We can also use the python function <code>enumerate()</code> to not only scroll through the <code>df</code> \
    column names, but also for counting the loop iterations starting from the first one (index 0). The iteration index \
    will be stored in the variable <code>i</code>.'
question_box(question=question,process=process,code=code,wiz=wiz_code)



for column_name in column_names:
    selected_column = df[column_name]
    selected_column_na = selected_column.isna()
    n_nan = selected_column_na.sum()
    print(column_name,'has',n_nan,'NaN')





for i,column_name in enumerate(column_names): \
    print(f"{i}) {column_name} has {df[column_name].isna().sum()} NaN")


#| echo: false
solution = 'The only column that does not have NaNs is the Voyage ID column, all the others (excluding the Year of Arrival [...]) have thousands of NaNs.'
question_box(solution=solution)





#| echo: false
task = 'Cleaning data'
process = list_to_html([
    'Remove all the data of the column VOYAGEID2;',
    'Go through all the values of the column "Captives arrived at 1st port" and remove rows containing NaNs;',
    'Go through all the values of the descriptive columns and change NaN into "unknown"',
    'Check how much data has been filtered out.'
])
tools = list_to_html([
    'Python function <code>print()</code>;',
    '<code>pandas</code> attribute <code>.columns</code>;',
    '<code>pandas</code> method <code>drop()</code>;',
    '<code>pandas</code> method <code>.head()</code>;',
    '<code>pandas</code> method <code>.dropna()</code>;',
    '<code>pandas</code> method <code>.fillna()</code>;',
    '<code>pandas</code> attribute <code>.shape</code>;',
    'Python function <code>len()</code>;',
    'Python operators * (multiplication), / (division), and - (subtraction)'
])
code_block1 = code_block([
'column_to_remove = "VOYAGEID2"',
'column_to_remove_nan = "Captives arrived at 1st port"'
])
code_block2 = code_block([
'print(cleaned_df.shape)',
'n_filtered_rows = len(df)-len(cleaned_df)',
'per_cent = (n_filtered_rows/len(df))*100'
])
code = list_to_html([
    '<code>print(df.columns)</code>, we start printing the name of our DataFrame columns, just as a reminder. We use \
    the Python function <code>print()</code> and the <code>pandas</code> attribute <code>.columns</code> that \
    we already used several times;',
    code_block1 + ', we store the name of the columns we are interested in into two variables. This is not stricktly \
    necessary, as we could use the name of the columns directly as input for methods and functions. However, with this \
    extra step, our code will be more readable as we are using two very descriptive variable names: <code>column_to_remove</code> \
    will, indeed, contain the name of the column we want to remove from our DataFrame (VOYAGEID2) and <code>column_to_remove_nan</code> \
    will contain the name of the column to use as a reference for filtering rows, all the rows having NaN in this column \
    will be removed;',
    '<code>cleaned_df_step1 = df.drop(column_to_remove,axis=1)</code>, we use the method <code>.drop()</code> to remove \
    a specific column. Each row of a <code>pandas</code> DataFrame has an index. This index is different from the index \
    that every Python list of objects has, i.e. an integer number starting from 0. This DataFrame index is an additional \
    index that can be not only a number, but also a string or a label. The <code>pandas</code> method <code>.drop()</code> \
    can be used either to remove columns, depending on column names, or rows, depending on <code>pandas</code> index. \
    To indicate that we want to target columns, and not rows, we need to specify the parameter <code>axis</code> equal \
    to 1 (0 would target the rows). Together with that, we also need to specify the name of the column we want to remove, stored \
    in the variable <code>column_to_remove</code>. In this way, we apply the method <code>.drop()</code> to our "dirty" \
    DataFrame <code>df</code> and we store the result into the variable <code>cleaned_df_step1</code>;',
    '<code>cleaned_df_step1.head(5)</code>, after every filtering operation, it is a good idea to check out the effect on \
    our output result. In this case we use the <code>pandas</code> method <code>.head()</code> to visualise the first five \
    rows of our DataFrame <code>cleaned_df_step1</code>',
    '<code>cleaned_df_step2 = cleaned_df_step1.dropna(subset=[column_to_remove_nan])</code>, we use the method <code>.dropna()</code> \
    to filter out all the rows having NaN in a list of columns. The list of columns needs to be specified in the function \
    parameter <code>subset</code>. In this case we have a single column name stored in the variable <code>column_to_remove_nana</code> \
    and to make it a list we put this variable in between square brackets <code>[ ]</code>. We apply the method to the \
    DataFrame <code>cleaned_df_step1</code> and store the result in <code>cleaned_df_step2</code>;',
    '<code>cleaned_df = cleaned_df_step2.fillna("unknown")</code>, we finally use the method <code>.fillna()</code> to fill all \
    the NaN in our DataFrame with a certain value, in this case the string (word) "unknown". We apply the method to the \
    DataFrame <code>cleaned_df_step2</code> and store the result into <code>cleaned_df</code>;',
    code_block2 + ', this block of Python instructions checks the size of our filtered DataFrame <code>cleaned_df</code> and \
    compares it with our original, raw, DataFrame <code>df</code>. We first visualise the size of <code>cleaned_df</code> \
    using the attribute <code>.shape</code>, then we obtain simply the number of rows of each DataFrame using the Python \
    function <code>len()</code>. We subtract the number of rows of the DataFrames before and after filtering to check how many \
    rows we filtered out and we store the result into the variable <code>n_filtered_rows</code>. We finally compute the percent \
    of filtered rows compared to the initial size of the DataFrame.'
])
question_box(task=task,process=process,tools=tools,code=code)


# Display the name of the columns first
print(df.columns)

# Select our target columns for clearning the data
column_to_remove = 'VOYAGEID2'
column_to_remove_nan = 'Captives arrived at 1st port'

# Perform Data Cleaning visualising the result step by step
# step1, removing column VOYAGEID2 from the DataFrame
cleaned_df_step1 = df.drop(column_to_remove,axis=1)
cleaned_df_step1.head(5)


# step2, removing all the rows haveing NaN in the "Captives arrived at 1st port" column
cleaned_df_step2 = cleaned_df_step1.dropna(subset=[column_to_remove_nan])
cleaned_df_step2.head(5)


# step3, changing all the other NaN into unknown
cleaned_df = cleaned_df_step2.fillna("unknown")
cleaned_df.head(5)


# step4, checking how much data we filtered out
print(cleaned_df.shape)
n_filtered_rows = len(df)-len(cleaned_df)
per_cent = (n_filtered_rows/len(df))*100
print('We filtered out: ',len(df)-len(cleaned_df),', corresponding to about', round(per_cent), '% of our initial data')






