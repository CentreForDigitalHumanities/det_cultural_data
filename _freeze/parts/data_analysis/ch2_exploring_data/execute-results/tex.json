{
  "hash": "4ff0895cf612de47ffb9794fe2efe04c",
  "result": {
    "markdown": "---\ntitle: \"Exploring data\"\nexecute:   \n  enabled: true\n  error: true\n  freeze: auto\n---\n\n\n\n## Previous steps {.unnumbered} \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\ndata_file = 'data/data.csv'\ndf = pd.read_csv(data_file)\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year of arrival at port of disembarkation</th>\n      <th>Voyage ID</th>\n      <th>Vessel name</th>\n      <th>Voyage itinerary imputed port where began (ptdepimp) place</th>\n      <th>Voyage itinerary imputed principal place of slave purchase (mjbyptimp)</th>\n      <th>Voyage itinerary imputed principal port of slave disembarkation (mjslptimp) place</th>\n      <th>VOYAGEID2</th>\n      <th>Captives arrived at 1st port</th>\n      <th>Captain's name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1714.0</td>\n      <td>16109</td>\n      <td>Freeke Gally</td>\n      <td>Bristol</td>\n      <td>NaN</td>\n      <td>Kingston</td>\n      <td>NaN</td>\n      <td>283.0</td>\n      <td>Neale, Alexander</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1713.0</td>\n      <td>16110</td>\n      <td>Greyhound Gally</td>\n      <td>Bristol</td>\n      <td>NaN</td>\n      <td>Jamaica, place unspecified</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Selkirk, Alexander&lt;br/&gt; Forrest, Henry</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1714.0</td>\n      <td>16111</td>\n      <td>Jacob</td>\n      <td>Bristol</td>\n      <td>NaN</td>\n      <td>Kingston</td>\n      <td>NaN</td>\n      <td>130.0</td>\n      <td>Nicholls, Philip</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1714.0</td>\n      <td>16112</td>\n      <td>Jason Gally</td>\n      <td>Bristol</td>\n      <td>NaN</td>\n      <td>Port Royal</td>\n      <td>NaN</td>\n      <td>278.0</td>\n      <td>Plummer, John</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1713.0</td>\n      <td>16113</td>\n      <td>Lawford Gally</td>\n      <td>Bristol</td>\n      <td>Africa, port unspecified</td>\n      <td>Newcastle (Nevis)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Stretton, Joseph</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow that we correctly loaded our data in our working environment, it is time to figure out what the data contains. It is always a good idea to look at the dataset [documentation](https://www.slavevoyages.org/voyage/about#methodology/introduction/0/en/) (or metadata) to understand where the data comes from, what is the source of all the different records, how data has been collected, and any other possible data related caveat. Diving into the data documentation is up to you, in this chapter what we want to do is understanding as much as we can from the data  itself, looking at its columns, rows, and values. <br>\nEvery dataset tells a story. You may think about it like a person with a long experience, but not really willing to talk (well, some datasets \"talk\" more easily than others). It is your role in this case to \"interrogate\" the data, let it to talk, to tell a story and to dive into the details of that story, getting as much information as you can. This also depends on how much you need to know: will you be satisfied by a small \"chat\" or you need to know all kind of details? <br>\nLet's formulate some questions to begin with.\n\n::: {.cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n<IPython.core.display.HTML object>\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n(36151, 9)\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nsolution = 'Our DataFrame contains data distributed in 36151 rows and 9 columns. '\nquestion_box(solution=solution)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<IPython.core.display.HTML object>\n```\n:::\n:::\n\n\nIt is a quite big dataset. Shall we care about how big is our dataset? We should as this may affect our analysis. For example, if we implement a scientific analysis that requires 1 second per row to produce an output, such program would take about 10hrs to analyse the entire dataset, and that is something we should keep in mind. That is why, in general, it is a good idea to test large analysis programs on a small sub-set of data and then, once verified that everything runs smoothly, to perform the analysis on the entire dataset.\n\nLet's continue exploring our DataFrame. We have 9 columns, we saw them displayed in our notebook and, luckily enough, their names are pretty descriptive, therefore, in this case, it is quite intuitive to understand what kind of information they contain. It could be useful to store the column names inside a Python variable and to display their names with a corresponding index (this will be useful later).\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n<IPython.core.display.HTML object>\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ncolumn_names = df.columns\nprint(column_names)\ni=0 \nprint(\"Index ) Column name\") \nfor name in column_names: \n    print(i,\")\",name) \n    i = i + 1 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIndex(['Year of arrival at port of disembarkation', 'Voyage ID', 'Vessel name',\n       'Voyage itinerary imputed port where began (ptdepimp) place',\n       'Voyage itinerary imputed principal place of slave purchase (mjbyptimp) ',\n       'Voyage itinerary imputed principal port of slave disembarkation (mjslptimp) place',\n       'VOYAGEID2', 'Captives arrived at 1st port', 'Captain's name'],\n      dtype='object')\nIndex ) Column name\n0 ) Year of arrival at port of disembarkation\n1 ) Voyage ID\n2 ) Vessel name\n3 ) Voyage itinerary imputed port where began (ptdepimp) place\n4 ) Voyage itinerary imputed principal place of slave purchase (mjbyptimp) \n5 ) Voyage itinerary imputed principal port of slave disembarkation (mjslptimp) place\n6 ) VOYAGEID2\n7 ) Captives arrived at 1st port\n8 ) Captain's name\n```\n:::\n:::\n\n\nNow we have the column names nicely listed from top to bottom and with their corresponding index assigned to them. You might be tempted to start the indexing from 1, but as in Python the first element of a list (or any other series of elements) has index 0, we started counting from zero. You can obtain the same result with less lines of code, try it out!\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nprint(\"Index) Column name\") \nfor i,name in enumerate(column_names): \n    print(f\"{i}) {name}\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIndex) Column name\n0) Year of arrival at port of disembarkation\n1) Voyage ID\n2) Vessel name\n3) Voyage itinerary imputed port where began (ptdepimp) place\n4) Voyage itinerary imputed principal place of slave purchase (mjbyptimp) \n5) Voyage itinerary imputed principal port of slave disembarkation (mjslptimp) place\n6) VOYAGEID2\n7) Captives arrived at 1st port\n8) Captain's name\n```\n:::\n:::\n\n\nIt is now time to figure out what are the rows about. Looking at the column names, we notice that the second one (index 1) is called \"Voyage ID\". This indicates that this column contains a specific identifier for the ship voyage, implying that each row contains specific information about a single trip. To verify that each row corresponds to a single voyage, we need to check if all the values of the Voyage ID column are different, i.e. if they are unique.<br>\n\n::: {.cell execution_count=10}\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n<IPython.core.display.HTML object>\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nvoyage_id = df.iloc[:,1]\nprint(voyage_id.is_unique)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrue\n```\n:::\n:::\n\n\nWe verified that all the values of the Voyage ID column are unique, this means that each of the rows of our DataFrame refers to a single ship voyage. Looking at the other columns, we also notice that information where the voyage began, the port where slaves have been purchased, and the port where slaves have been desembarked is provided.<br>\nLooking in particular at the fifth column (index 4, \"Voyage itinerary imputed principal place of slave purchase\"), we notice it contains several NaNs. NaN stands for \"Not a Number\", it is a value that appears when something goes wrong in one of the processes ran by our program. If something went wrong, why did not our program stop or told us something about an occuring problem? Because problems may happen more often than you think and if our program stops working everytime it encounters a situation it cannot handle, it would most probably never finish running! In this case, most probably the record does not exist so the data set cell has been filled by NaN, either in our original .csv file or by the ```pandas``` method ```.read_csv()```. NaN are not necesseraly something bad, as they can be easily identified and eventually corrected (or simply ignored). Incorrect or missing data may be much harder to spot and correct. <br>\nIn any case, the presence of NaNs or any other missing value can severely affect our data analysis, for this reason before starting analysing the data we need to find and get rid of those values. This process is usually called \"data cleaning\" and that is exactly what we are going to do in the next chapter.\n\n\n",
    "supporting": [
      "ch2_exploring_data_files/figure-pdf"
    ],
    "filters": []
  }
}